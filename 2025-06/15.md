
# [BE] 느려진 서비스, 어디부터 봐야 할까?

**작성일**: 2025. 6. 15  
**출처**: 최범균님의 『주니어 백엔드 개발자가 반드시 알아야 할 실무 지식』

---

## 🎯 성능 지표의 핵심: 응답시간 & 처리량

### 1. 응답시간(Response Time)
- **정의**: 한 사용자의 요청을 처리하는 데 걸리는 시간
- **경로**: `Client → API 서버 → DBMS → API 서버 → Client`
- **측정**: 
  - `TTFB` (Time to First Byte)
  - `TTLB` (Time to Last Byte)
- **영향 요인**: 서버 로직, 네트워크, DB, 외부 API 등  
  ⏱ 전체 시간의 70~80%는 DB, 외부 API에 소요됨

➡ **DB와 외부 API를 집중 최적화** 해야 함

---

### 2. 처리량(Throughput)
- **정의**: 단위 시간당 처리 가능한 요청 수
- **단위**: TPS(Transaction/sec), RPS(Response/sec)
- **한계**: 최대 TPS 초과 시 요청이 큐에 대기됨

### 해결 방안
1. 처리 시간 자체를 줄인다
2. 서버의 동시 처리 능력을 확장한다 (예: 스레드 수 증가)

---

## 🔍 병목 지점 탐색

- 초기에는 문제 없지만 트래픽 증가 시 병목 발생
- 병목 위치: DB, 외부 API, 느린 코드
- **해결 방법**:
  - 수직 확장: CPU, RAM 등 자원 업그레이드
  - 수평 확장: 로드 밸런서로 서버 분산 처리
    - **정적 분산**: IP 해시, 라운드 로빈 등
    - **동적 분산**: 헬스체크 기반 동적 트래픽 분산

---

## 🔗 커넥션 풀 설정

### 커넥션 풀 주요 설정
1. **최소/최대 커넥션 수**:
   - 트래픽 특성에 따라 조절 (낮: 은행, 밤: 게임)
   - 급증 시 최소=최대로 설정 → 생성 비용 감소

2. **커넥션 대기 시간**:
   - 너무 길면 응답시간 증가
   - 짧게 설정해 사용자 반응성 ↑

3. **최대 유휴/유지 시간**:
   - DB보다 짧게 설정 → 비활성 커넥션 제거
   - 유효성 검사 설정 중요

---

## 🧵 스레드 풀 설정 (Tomcat 예시)
- `minSpareThreads`: 최소 대기 워커 스레드 수
- `maxThreads`: 동시에 처리 가능한 최대 요청 수

---

## 📦 캐시 사용 전략

### 1. 서버 캐시
- **로컬 캐시** (e.g. Caffeine):
  - 빠르지만 서버 재시작 시 캐시 초기화
- **리모트 캐시** (e.g. Redis):
  - 안정적이고 유연한 스케일, 네트워크 I/O 존재

### 2. 캐시 성능 측정
- **Hit Rate** = (캐시 적중 수 / 전체 요청 수)
- **전략**:
  - LRU, LFU 알고리즘
  - TTL 설정

---

## 🧹 GC와 성능

### 1. G1GC (Garbage-First)
- 힙을 여러 Region으로 나눔
- 가비지가 많은 영역부터 먼저 수거
- 병렬 처리로 STW 시간 단축

### 2. ZGC
- STW 1~2ms 이하 유지
- 대용량 힙에 적합 (TB급)
- 간접 참조 및 메타데이터 관리

---

## 📡 네트워크 최적화

### 데이터 압축
- 텍스트 데이터에 효과적 (HTML, JSON 등)
- 이미지/압축 파일에는 효과 미미
- `Accept-Encoding`, `Content-Encoding` 헤더로 제어

### 정적 자산 캐시
- `Cache-Control` 헤더 활용 → 브라우저/클라이언트 캐시
- `CDN` (CloudFront, Cloudflare 등) 통해 캐싱 범위 확장
- CDN → 원본 서버 트래픽 감소

---

📌 **결론**  
서비스 성능 문제는 단순히 서버 로직이 아닌 외부 의존성, 네트워크, 캐시, DB의 설정 등 다양한 요소에서 비롯됩니다. 모니터링 도구와 지표 분석을 통해 병목 지점을 정확히 파악하고, 상황에 맞는 수직/수평 확장, 캐싱 전략, GC 튜닝, 커넥션 관리가 핵심입니다.
